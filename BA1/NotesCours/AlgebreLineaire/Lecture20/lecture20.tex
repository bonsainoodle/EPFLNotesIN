\documentclass[a4paper]{article}

% Expanded on 2021-11-29 at 13:15:27.

\usepackage{../../style}

\title{Algèbre linéaire}
\author{Joachim Favre}
\date{Lundi 29 novembre 2021}

\begin{document}
\maketitle

\lecture{20}{2021-11-29}{Kernel, image, famille et espace orthogonal}{
}

\parag{Observation}{
    On voit que:
    \[\bvec{v}^T \bvec{x} = \bvec{v} \dotprod \bvec{x} \]
}

\parag{Théorème}{
    Soit une matrice $A$ quelconque. On a:
    \[\left(\im\left(A^T\right)\right)^{\perp} = \ker A \]
}

\parag{Corollaire}{
    Soit $A$ une matrice. On a:
    \begin{itemize}
        \item $\left(\ker A\right)^{\perp} = \im\left(A^T\right)$
        \item $\left(\im A\right)^{\perp} = \ker\left(A^T\right)$
        \item $\left(\ker A^T\right)^{\perp} = \im\left(A\right)$
        \item $\left(\im A^T\right)^{\perp} = \ker\left(A\right)$
    \end{itemize}

    On remarque que pour chaque égalité on a échangé $\ker$ et $\im$, on a échangé $A$ et $A^T$, et on a échangé $V$ et $V^{\perp}$.
}


\parag{Théorème d'Al Kashi}{
    On sait que, dans n'importe quel triangle:
    \[a^2 + b^2 - 2ab \cos\left(\gamma\right) = c^2\]
    où $\gamma$ est l'angle opposé au côté $c$ (donc l'angle entre le côté $a$ et le côté $b$).

    Ce théorème est appelé le théorème d'Al Kashi, le théorème des cosinus ou, par certains hérétiques, le théorème de Pythagore généralisé.

    \subparag{Implication}{
        On peut donc en déduire que:
        \[\bvec{u} \dotprod \bvec{v} = \left\|\bvec{u}\right\| \left\|\bvec{v}\right\| \cos \theta\]
    }
}

\subsection{Familles orthogonales}

\parag{Définition}{
    Des vecteurs $\left(\bvec{u}_1, \ldots, \bvec{u}_p\right)$ de $\mathbb{R}^n$ forment une \important{famille orthogonale} si chaque vecteur est orthogonal à tous les autres, c'est-à-dire si:
    \[\bvec{u}_i \dotprod \bvec{u}_j = 0, \mathspace \forall i \forall j, i \neq j\]

    \subparag{Remarque}{
        Comme $\bvec{0} \dotprod \bvec{u} = \bvec{0}$ pour tout $\bvec{u}$, on peut très bien avoir des vecteurs nuls dans une famille orthogonale.
    }
}

\parag{Théorème}{
    Si les vecteurs $\left(\bvec{u}_1, \ldots, \bvec{u}_p\right)$ sont \textit{tous} non-nuls et forment une famille orthogonale, alors ils sont linéairement indépendants.
}

\parag{Définition}{
    Soit $\left(\bvec{u}_1, \ldots, \bvec{u}_p\right)$ une base d'un sous-espace $W$ de $\mathbb{R}^n$. Si cette famille est orthogonale, on dit qu'elle forme une \important{base orthogonale} de $W$.
}

\parag{Théorème}{
    Soit $\left(\bvec{u}_1, \ldots, \bvec{u}_p\right)$ une base orthogonale d'un sous-espace vectoriel $W$ de $\mathbb{R}^n$. Pour tout $\bvec{y}$ de $W$, les coefficients de la combinaison linéaire $\bvec{y} = c_1 \bvec{u}_1 + \ldots + c_p \bvec{u}_p$ sont données par la relation:
    \[c_j = \frac{\bvec{y} \dotprod \bvec{u}_j}{\bvec{u}_j \dotprod \bvec{u}_j}, \mathspace j = 1, \ldots, p\]
}

\subsection{Projections orthogonales}

\end{document}
