\documentclass[a4paper]{article}

% Expanded on 2021-11-08 at 13:10:18.

\usepackage{../../style}

\title{Algèbre linéaire}
\author{Joachim Favre}
\date{Lundi 08 novembre 2021}

\begin{document}
\maketitle

\lecture{14}{2021-11-08}{Changements de base et applications linéaires}{
}

\parag{Sous-espaces intéressants}{
    On commence à réaliser qu'il y a \important{quatre sous-espaces} intéressants pour une matrice $A \in \mathbb{R}^{m \times n}$:
    \begin{itemize}
        \item $\im A^T$ et $\ker A$, sous-espaces de $\mathbb{R}^{n}$, et tels que:
              \[\dim\im A^T + \dim\ker A = n\]

        \item $\im A$ et $\ker A^T$, sous-espaces de $\mathbb{R}^{m}$, et tels que:
              \[\dim\im A + \dim\ker A^T = m\]
    \end{itemize}
}

\parag{Résumé}{
    Nous pouvons résumer ce que nous avons fait à l'aide des théorèmes suivants.

    \subparag{Théorème 1}{
        Si $A$ et $B$ sont deux matrices équivalentes selon les lignes, alors leur lignes engendrent le même espace. Si $B$ est échelonnée, alors les lignes non-nulles de $B$ forment une base de cet espace.
    }

    \subparag{Théorème 2}{
        Soit $A$ une matrice $m \times n$. L'espace engendré par les colonnes de $A$ et l'espace engendré par les lignes de cette matrice ont la même dimension. Cette dimension commune, le rang de $A$, est égale au nombre de positons pivots de $A$ et vérifie la relation :
        \[\rang A + \dim\ker A = n \iff \rang A + \dim\ker A^T = m\]

    }

    \subparag{Théorème 3 (suite du grand théorème)}{
        Soit $A$ une matrice $n \times n$. Les propriétés suivantes sont équivalentes :

        \begin{enumerate}[left=0pt]
            \item $A$ est inversible.
            \item $A$ est équivalente selon les lignes à la matrice unité $n \times n$, $I_n$.
            \item $A$ admet $n$ positions de pivot.
            \item L'équation $A \bvec{x} = \bvec{0}$ admet la solution triviale pour unique solution.
            \item Les colonnes de $A$ sont linéairement indépendantes.
            \item L'application $\bvec{x} \mapsto A \bvec{x}$ est injective.
            \item Pour tout vecteur $\bvec{b} \in \mathbb{R}^{n}$, l'équation $A \bvec{x} = \bvec{b}$ admet au moins une solution (on aurait aussi pu dire ``une solution unique'', ou au plus une solution).
            \item Les colonnes de $A$ engendrent $\mathbb{R}^{n}$.
            \item L'application linéaire $x \mapsto A \bvec{x}$ est surjective.
            \item Il existe une matrice $C$ de taille $n \times n$ telle que $CA = I_n$.
            \item Il existe une matrice $D$ de taille $n \times n$ telle que $AD = I_n$.
            \item $A^T$ est inversible.
            \item Les colonnes de $A$ forment une base de $\mathbb{R}^{n}$.
            \item $\im A = \mathbb{R}^{n}$
            \item $\dim\im A = n$
            \item $\rang A = n$
            \item $\ker A = \left\{\bvec{0}\right\}$
            \item $\dim\ker A = 0$
        \end{enumerate}

    }
}

\subsection{Changements de base}

\parag{Théorème}{
    Soit $\mathcal{B} = \left(\bvec{b}_1, \ldots, \bvec{b}_n\right)$ et $\mathcal{C} = \left(\bvec{c}_1, \ldots, \bvec{c}_n\right)$ deux bases d'un espace vectoriel $V$. Il existe une matrice $n \times n$ unique, notée $\matricepassage{C}{B}$, telle que pour tout vecteur $\bvec{x} \in V$:
    \[\left[\bvec{x}\right]_{\mathcal{C}} = \matricepassage{C}{B}\left[\bvec{x}\right]_{\mathcal{B}}\]

    Les colonnes de $\matricepassage{C}{B}$ sont les colonnes de composantes, dans la base $\mathcal{C}$, des vecteurs de la base $\mathcal{B}$. Autrement dit:
    \[\matricepassage{C}{B} = \begin{bmatrix}  &  &  \\ \left[\bvec{b}_1\right]_{\mathcal{C}} & \ldots & \left[\bvec{b}_n\right]_{\mathcal{C}} \\  &  &  \end{bmatrix} \]
}

\parag{Inverse de la matrice de passage}{
    La matrice suivante passe de $\mathcal{B}$ à $\mathcal{C}$:
    \[\matricepassage{C}{B} = \begin{bmatrix}  &  &  \\ \left[\bvec{b}_1\right]_{\mathcal{C}} & \ldots & \left[\bvec{b}_n\right]_{\mathcal{C}} \\  &  &  \end{bmatrix} \]

    De plus, la matrice suivante passe de $\mathcal{C}$ à $\mathcal{B}$:
    \[\matricepassage{B}{C} = \begin{bmatrix}  &  &  \\ \left[\bvec{c}_1\right]_{\mathcal{B}} & \ldots & \left[\bvec{c}_n\right]_{\mathcal{B}} \\  &  &  \end{bmatrix} \]

    On remarque que leur produit donne la matrice identité, puisque cela correspond à transformer les coordonnées de $\bvec{x}$ de la base $\mathcal{B}$ vers la base $\mathcal{C}$, puis de la matrice $\mathcal{C}$ vers la base $\mathcal{B}$ ; donc, on n'a pas bougé:
    \[\matricepassage{B}{C}\matricepassage{C}{B} = I_n\]

    On peut donc en déduire que:
    \[\left(\matricepassage{C}{B}\right)^{-1} = \matricepassage{B}{C} \iff \left(\matricepassage{B}{C}\right)^{-1} = \matricepassage{C}{B} \]
}

\subsection{Applications linéaires d'espaces quelconques}

\parag{Théorème}{
    Soit $T: V \mapsto W$ une application linéaire et soient $\mathcal{V}$ et $\mathcal{W}$ des bases de $V$ et $W$, respectivement. Il existe une matrice unique (on a eu aucun choix à faire) $A$ telle que, pour tout $\bvec{x} \in V$:
    \[\left[T\left(\bvec{x}\right)\right]_{\mathcal{W}} = A \left[\bvec{x}\right]_{\mathcal{V}}\]

    Cette matrice est donnée par :
    \[A = \begin{bmatrix}  &  &  \\ \left[T\left(\bvec{v}_1\right)\right]_{\mathcal{W}} & \ldots & \left[T\left(\bvec{v}_n\right)\right]_{\mathcal{W}} \\  &  &  \end{bmatrix} \]
    où $\bvec{v}_1, \ldots, \bvec{v}_n$ sont les vecteurs de la base $\mathcal{V}$.

}

\end{document}
